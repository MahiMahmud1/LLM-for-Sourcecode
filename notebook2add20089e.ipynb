{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:30:37.420795Z","iopub.execute_input":"2025-08-21T07:30:37.421316Z","iopub.status.idle":"2025-08-21T07:30:37.425947Z","shell.execute_reply.started":"2025-08-21T07:30:37.421289Z","shell.execute_reply":"2025-08-21T07:30:37.425315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers accelerate datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:30:37.427337Z","iopub.execute_input":"2025-08-21T07:30:37.427535Z","iopub.status.idle":"2025-08-21T07:30:40.931821Z","shell.execute_reply.started":"2025-08-21T07:30:37.427520Z","shell.execute_reply":"2025-08-21T07:30:40.930848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the MBPP dataset\ndataset = load_dataset(\"mbpp\", split=\"train\")\n\n# Check a sample\nprint(dataset[0])\nfrom datasets import load_dataset\n\n# Load the MBPP dataset (train split)\ndataset = load_dataset(\"mbpp\", split=\"train\")\n\n# Check column names and first example\nprint(\"Columns:\", dataset.column_names)\nprint(\"First example:\", dataset[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:30:40.932783Z","iopub.execute_input":"2025-08-21T07:30:40.933070Z","iopub.status.idle":"2025-08-21T07:30:46.247506Z","shell.execute_reply.started":"2025-08-21T07:30:40.933047Z","shell.execute_reply":"2025-08-21T07:30:46.246756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load MBPP\ndataset = load_dataset(\"mbpp\", split=\"train\")\n\n# Print column names\nprint(dataset.column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:30:46.248955Z","iopub.execute_input":"2025-08-21T07:30:46.249170Z","iopub.status.idle":"2025-08-21T07:30:48.655894Z","shell.execute_reply.started":"2025-08-21T07:30:46.249153Z","shell.execute_reply":"2025-08-21T07:30:48.655308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Map columns to text-to-text format\ntrain_data = dataset.map(lambda x: {'input_text': x['text'], 'target_text': x['code']})\n\n# Keep only necessary columns\ntrain_data = train_data.remove_columns([col for col in train_data.column_names if col not in ['input_text', 'target_text']])\n\n# Verify preprocessing\nprint(train_data[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:30:48.657863Z","iopub.execute_input":"2025-08-21T07:30:48.658299Z","iopub.status.idle":"2025-08-21T07:30:48.666926Z","shell.execute_reply.started":"2025-08-21T07:30:48.658280Z","shell.execute_reply":"2025-08-21T07:30:48.666392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_name = \"Salesforce/codet5-base\"\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\nprint(f\"Model {model_name} loaded successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:30:48.667570Z","iopub.execute_input":"2025-08-21T07:30:48.667789Z","iopub.status.idle":"2025-08-21T07:30:50.262701Z","shell.execute_reply.started":"2025-08-21T07:30:48.667769Z","shell.execute_reply":"2025-08-21T07:30:50.261959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenize input and target for CodeT5\ndef preprocess(example):\n    return tokenizer(\n        example['input_text'],\n        text_target=example['target_text'],\n        truncation=True,\n        padding='max_length',\n        max_length=256\n    )\n\ntrain_data = train_data.map(preprocess, batched=True)\n\n# Verify a sample after tokenization\nprint(train_data[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:30:50.263560Z","iopub.execute_input":"2025-08-21T07:30:50.263814Z","iopub.status.idle":"2025-08-21T07:30:50.295312Z","shell.execute_reply.started":"2025-08-21T07:30:50.263787Z","shell.execute_reply":"2025-08-21T07:30:50.294631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments, TrainerCallback\nfrom datetime import datetime\n\n# Optional: small subset for faster fine-tuning\ntrain_subset = train_data.select(range(300))  # first 300 examples only\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=2,            \n    per_device_train_batch_size=2,\n    save_total_limit=1,\n    report_to=[],  \n)\n\n\n# Custom callback to log timestamp\nclass TimeLoggingCallback(TrainerCallback):\n    def on_log(self, args, state, control, logs=None, **kwargs):\n        # Print timestamp whenever logs are generated\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        print(f\"[{timestamp}] Step {state.global_step}: {logs}\")\n\n# Create Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_subset,\n    callbacks=[TimeLoggingCallback()]  # Add timestamp logging\n)\n\n# Start fine-tuning\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:31:15.296979Z","iopub.execute_input":"2025-08-21T07:31:15.297814Z","iopub.status.idle":"2025-08-21T07:32:40.898569Z","shell.execute_reply.started":"2025-08-21T07:31:15.297785Z","shell.execute_reply":"2025-08-21T07:32:40.897965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\n# Create the text-to-text generation pipeline using pre-trained CodeT5\ngen = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\nprint(\"Code generation pipeline ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:35:31.668719Z","iopub.execute_input":"2025-08-21T07:35:31.669316Z","iopub.status.idle":"2025-08-21T07:35:31.681421Z","shell.execute_reply.started":"2025-08-21T07:35:31.669291Z","shell.execute_reply":"2025-08-21T07:35:31.680784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\n\n# Improved problem description with example\nproblem = \"\"\"\n# Python function\n# Task: generate all even integers between a and b inclusive\n# The function should return a list in ascending order\n# Example: generate_integers(2, 6) -> [2, 4, 6]\ndef generate_integers(a, b):\n\"\"\"\n\ndef generate_code(problem_description):\n    # Generate code using fine-tuned CodeT5\n    result = gen(problem_description, max_new_tokens=256)\n    # Get current timestamp\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    return result[0]['generated_text'], timestamp\n\n# Generate code\ngenerated_code, timestamp = generate_code(problem)\nprint(f\"Generated Code at {timestamp}:\")\nprint(generated_code)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:36:52.333756Z","iopub.execute_input":"2025-08-21T07:36:52.334372Z","iopub.status.idle":"2025-08-21T07:36:54.490553Z","shell.execute_reply.started":"2025-08-21T07:36:52.334347Z","shell.execute_reply":"2025-08-21T07:36:54.489826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Store generated code in a DataFrame\nresults = [{\"task\": \"generate_integers\", \"generated_code\": generated_code}]\ndf_results = pd.DataFrame(results)\n\n# Save results\nout_path = \"/kaggle/working/codet5_mbpp_results.csv\"\ndf_results.to_csv(out_path, index=False)\nprint(\"Results saved to:\", out_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:35:43.122457Z","iopub.execute_input":"2025-08-21T07:35:43.122721Z","iopub.status.idle":"2025-08-21T07:35:43.128643Z","shell.execute_reply.started":"2025-08-21T07:35:43.122700Z","shell.execute_reply":"2025-08-21T07:35:43.127976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_problem = \"\"\"\n# Python function\n# Task: check if a number is a palindrome\n# The function should return True if number is palindrome, otherwise False\n# Example: is_palindrome(121) -> True\ndef is_palindrome(n):\n    # Your code here\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:40:48.456951Z","iopub.execute_input":"2025-08-21T07:40:48.457501Z","iopub.status.idle":"2025-08-21T07:40:48.461158Z","shell.execute_reply.started":"2025-08-21T07:40:48.457477Z","shell.execute_reply":"2025-08-21T07:40:48.460547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate code for your custom problem\ngenerated_code, timestamp = generate_code(new_problem)\nprint(f\"Generated Code at {timestamp}:\")\nprint(generated_code)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:40:52.882070Z","iopub.execute_input":"2025-08-21T07:40:52.882337Z","iopub.status.idle":"2025-08-21T07:40:54.811719Z","shell.execute_reply.started":"2025-08-21T07:40:52.882319Z","shell.execute_reply":"2025-08-21T07:40:54.811110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = gen(new_problem, max_new_tokens=256, num_return_sequences=3)\nfor i, r in enumerate(results):\n    print(f\"Candidate {i+1}:\\n{r['generated_text']}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:41:39.364627Z","iopub.execute_input":"2025-08-21T07:41:39.365091Z","iopub.status.idle":"2025-08-21T07:41:40.133969Z","shell.execute_reply.started":"2025-08-21T07:41:39.365068Z","shell.execute_reply":"2025-08-21T07:41:40.133311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\n\ndef generate_code(problem_description, num_candidates=1):\n    \"\"\"\n    problem_description: str, the problem text including function signature\n    num_candidates: int, number of code versions to generate\n    \"\"\"\n    results = gen(problem_description, max_new_tokens=256, num_return_sequences=num_candidates)\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    \n    # Return a list of tuples (code, timestamp)\n    return [(r['generated_text'], timestamp) for r in results]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:45:30.539621Z","iopub.execute_input":"2025-08-21T07:45:30.540356Z","iopub.status.idle":"2025-08-21T07:45:30.544586Z","shell.execute_reply.started":"2025-08-21T07:45:30.540329Z","shell.execute_reply":"2025-08-21T07:45:30.543780Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_problem = \"\"\"\n# Python function\n# Task: find the largest number among three numbers\n# The function should return the largest of the three numbers\n# Example: max_of_three(3, 7, 5) -> 7\ndef max_of_three(a, b, c):\n    # Your code here\n\"\"\"\n\n# Generate 1 candidate\ngenerated_results = generate_code(new_problem, num_candidates=1)\n\n# Print the output\nfor code, ts in generated_results:\n    print(f\"Generated Code at {ts}:\\n{code}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:45:59.291606Z","iopub.execute_input":"2025-08-21T07:45:59.291852Z","iopub.status.idle":"2025-08-21T07:46:01.358080Z","shell.execute_reply.started":"2025-08-21T07:45:59.291834Z","shell.execute_reply":"2025-08-21T07:46:01.357438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generated_results = generate_code(new_problem, num_candidates=3)\nfor i, (code, ts) in enumerate(generated_results):\n    print(f\"Candidate {i+1} at {ts}:\\n{code}\\n{'-'*50}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T07:46:31.157358Z","iopub.execute_input":"2025-08-21T07:46:31.157606Z","iopub.status.idle":"2025-08-21T07:46:33.277702Z","shell.execute_reply.started":"2025-08-21T07:46:31.157589Z","shell.execute_reply":"2025-08-21T07:46:33.276952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"problems = [\n    {\n        \"task\": \"palindrome_check\",\n        \"description\": \"\"\"\n# Python function\n# Task: check if a number is palindrome\n# Example: is_palindrome(121) -> True\ndef is_palindrome(n):\n    # Your code here\n\"\"\"\n    },\n    {\n        \"task\": \"fibonacci_n\",\n        \"description\": \"\"\"\n# Python function\n# Task: return nth Fibonacci number\n# Example: fibonacci_n(6) -> 8\ndef fibonacci_n(n):\n    # Your code here\n\"\"\"\n    },\n    {\n        \"task\": \"factorial\",\n        \"description\": \"\"\"\n# Python function\n# Task: return factorial of n\n# Example: factorial(5) -> 120\ndef factorial(n):\n    # Your code here\n\"\"\"\n    },\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T08:18:20.068551Z","iopub.execute_input":"2025-08-21T08:18:20.069064Z","iopub.status.idle":"2025-08-21T08:18:20.072996Z","shell.execute_reply.started":"2025-08-21T08:18:20.069043Z","shell.execute_reply":"2025-08-21T08:18:20.072393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\n\nfor p in problems:\n    generated_result = gen(p[\"description\"], max_new_tokens=64, num_return_sequences=1)\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    code = generated_result[0]['generated_text']\n    \n    print(f\"Task: {p['task']} | Generated at {timestamp}\")\n    print(code)\n    print(\"-\"*50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T08:18:37.961725Z","iopub.execute_input":"2025-08-21T08:18:37.962075Z","iopub.status.idle":"2025-08-21T08:18:41.901245Z","shell.execute_reply.started":"2025-08-21T08:18:37.962052Z","shell.execute_reply":"2025-08-21T08:18:41.900599Z"}},"outputs":[],"execution_count":null}]}